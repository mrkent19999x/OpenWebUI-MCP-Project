# Danh S√°ch Ngu·ªìn AI Mi·ªÖn Ph√≠ M·ªõi Nh·∫•t 2025
## (Quota Cao, Kh√¥ng C·∫ßn Th·∫ª T√≠n D·ª•ng)

*C·∫≠p nh·∫≠t: Th√°ng 11/2025*

### üèÜ TOP NGU·ªíN KHUY·∫æN NGH·ªä (Quota Cao Nh·∫•t)

#### 1. **Cerebras** - ü•á *Quota Kh·ªßng Nh·∫•t*
- **Website**: https://cerebras.ai
- **ƒêƒÉng k√Ω**: Kh√¥ng c·∫ßn th·∫ª t√≠n d·ª•ng
- **Free Tier**: 1 tri·ªáu tokens/ng√†y (c·ª±c k·ª≥ h√†o ph√≥ng)
- **Rate Limit**: 600 requests/ph√∫t
- **Context**: 65K tokens
- **Models**: Llama 3.1, Qwen, v√† nhi·ªÅu model hi·ªán ƒë·∫°i
- **∆Øu ƒëi·ªÉm**: T·ªëc ƒë·ªô inference nhanh nh·∫•t th·∫ø gi·ªõi
- **OpenAI Compatible**: ‚úÖ

#### 2. **Cloudflare Workers AI** - ü•à *·ªîn ƒê·ªãnh & Mi·ªÖn Ph√≠ Vƒ©nh Vi·ªÖn*
- **Website**: https://dash.cloudflare.com/ai
- **ƒêƒÉng k√Ω**: Cloudflare account mi·ªÖn ph√≠
- **Free Tier**: 10,000 Neurons/ng√†y (t∆∞∆°ng ƒë∆∞∆°ng ~50K tokens)
- **Rate Limit**: 100 requests/ph√∫t
- **Models**: Llama 3.1, Mixtral, Stable Diffusion
- **∆Øu ƒëi·ªÉm**: Kh√¥ng gi·ªõi h·∫°n th·ªùi gian, infrastructure to√†n c·∫ßu
- **OpenAI Compatible**: ‚úÖ

#### 3. **GitHub Models** - ü•â *D·ªÖ ƒêƒÉng K√Ω Nh·∫•t*
- **Website**: https://github.com/features/copilot/models
- **ƒêƒÉng k√Ω**: Ch·ªâ c·∫ßn GitHub account
- **Free Tier**: Gi·ªõi h·∫°n theo rate limit, kh√¥ng c·∫ßn credit
- **Rate Limit**: 20 requests/ph√∫t cho free models
- **Models**: GPT-4o mini, Claude 3.5, Llama 3.1
- **∆Øu ƒëi·ªÉm**: T√≠ch h·ª£p GitHub ecosystem
- **OpenAI Compatible**: ‚úÖ

---

### üìä DANH S√ÅCH NGU·ªíN ƒê·∫¶Y ƒê·ª¶ (C·∫≠p Nh·∫≠t 2025)

| Ngu·ªìn | Quota/ng√†y | Rate Limit | ƒêƒÉng k√Ω | OpenAI Compatible | ƒê√°nh gi√° |
|-------|------------|------------|---------|-------------------|----------|
| **Cerebras** | 1M tokens | 600 RPM | D·ªÖ | ‚úÖ | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **Cloudflare AI** | 10K neurons | 100 RPM | D·ªÖ | ‚úÖ | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **GitHub Models** | Rate limited | 20 RPM | R·∫•t d·ªÖ | ‚úÖ | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **OpenRouter** | 50 requests | 20 RPM | Trung b√¨nh | ‚úÖ | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **Google AI Studio** | 15 requests | 15 RPM | Trung b√¨nh | ‚úÖ | ‚≠ê‚≠ê‚≠ê |
| **Together AI** | $25 credits | 60 RPM | D·ªÖ | ‚úÖ | ‚≠ê‚≠ê‚≠ê |
| **DeepInfra** | Pay-per-use | 200 concurrent | D·ªÖ | ‚úÖ | ‚≠ê‚≠ê‚≠ê |
| **Replicate** | Gi·ªõi h·∫°n | 600 RPM | D·ªÖ | ‚úÖ | ‚≠ê‚≠ê |
| **Puter.js** | Unlimited* | Kh√¥ng gi·ªõi h·∫°n | R·∫•t d·ªÖ | ‚úÖ | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |

---

### üîß H∆Ø·ªöNG D·∫™N T√çCH H·ª¢P OPEN WEBUI

#### B∆∞·ªõc 1: ƒêƒÉng K√Ω Nhi·ªÅu Ngu·ªìn (15 ph√∫t)
```bash
# T·∫°o t√†i kho·∫£n theo th·ª© t·ª± ∆∞u ti√™n:
1. Cerebras.ai - ƒêƒÉng nh·∫≠p ‚Üí API Keys ‚Üí Create new key
2. Cloudflare - Workers AI ‚Üí Get started ‚Üí API token
3. GitHub Models - github.com ‚Üí Features ‚Üí Models ‚Üí Try it
4. OpenRouter - openrouter.ai ‚Üí Keys ‚Üí Create key
5. Google AI Studio - aistudio.google.com ‚Üí Get API key
```

#### B∆∞·ªõc 2: C·∫•u H√¨nh Open WebUI

**C√°ch 1: Th√™m t·ª´ng ngu·ªìn ri√™ng l·∫ª**
```
Settings ‚Üí Connections ‚Üí Add Connection ‚Üí OpenAI API

# Cerebras
Base URL: https://api.cerebras.ai/v1
API Key: [your-cerebras-key]

# Cloudflare Workers AI  
Base URL: https://api.cloudflare.com/client/v4/accounts/YOUR_ACCOUNT_ID/ai/v1
API Key: [your-cloudflare-token]

# GitHub Models
Base URL: https://models.inference.ai.azure.com
API Key: [your-github-token]
```

**C√°ch 2: D√πng LiteLLM Proxy (Khuy·∫øn ngh·ªã)**
```yaml
# config.yaml cho LiteLLM
model_list:
  - model_name: cerebras-llama
    litellm_params:
      model: cerebras/llama-3.1-70b
      api_base: https://api.cerebras.ai/v1
      api_key: ${CEREBRAS_API_KEY}
  
  - model_name: cloudflare-llama
    litellm_params:
      model: cloudflare/llama-3.1-8b-instruct
      api_base: https://api.cloudflare.com/client/v4/accounts/${CF_ACCOUNT_ID}/ai/v1
      api_key: ${CF_API_KEY}
  
  - model_name: github-gpt4o
    litellm_params:
      model: github/gpt-4o-mini
      api_base: https://models.inference.ai.azure.com
      api_key: ${GITHUB_TOKEN}

general_settings:
  database_url: sqlite:///./litellm.db
  master_key: your-secret-key
```

**Ch·∫°y LiteLLM Proxy:**
```bash
# Docker (Khuy·∫øn ngh·ªã)
docker run -p 4000:4000 -v $(pwd)/config.yaml:/app/config.yaml \
  -e CEREBRAS_API_KEY=your-key \
  -e CF_API_KEY=your-key \
  ghcr.io/berriai/litellm:main-latest \
  --config /app/config.yaml

# Ho·∫∑c local
pip install litellm
litellm --config config.yaml
```

**C·∫•u h√¨nh Open WebUI v·ªõi LiteLLM:**
```
Settings ‚Üí Connections ‚Üí Add Connection ‚Üí OpenAI API
Base URL: http://localhost:4000
API Key: your-secret-key (t·ª´ config.yaml)
```

---

### üöÄ CHI·∫æN L∆Ø·ª¢C T·ªêI ∆ØU S·ª¨ D·ª§NG

#### 1. **Rotation T·ª± ƒê·ªông**
```yaml
# liteLLM routing v·ªõi health check
model_list:
  - model_name: primary-llm
    litellm_params:
      model: cerebras/llama-3.1-70b
      api_base: https://api.cerebras.ai/v1
      api_key: ${CEREBRAS_API_KEY}
  
  - model_name: fallback-llm
    litellm_params:
      model: cloudflare/llama-3.1-8b-instruct
      api_base: https://api.cloudflare.com/client/v4/accounts/${CF_ACCOUNT_ID}/ai/v1
      api_key: ${CF_API_KEY}

# Health check v√† auto-fallback
litellm_params:
  num_retries: 3
  request_timeout: 30
```

#### 2. **Caching Th√¥ng Minh**
```python
# Trong Open WebUI
Settings ‚Üí Functions ‚Üí Enable Response Caching
# Gi·∫£m 60% API calls cho c√¢u h·ªèi t∆∞∆°ng t·ª±
```

#### 3. **Ch·ªçn Model Ph√π H·ª£p**
- **C√¥ng vi·ªác nh·∫π**: Llama 3.1 8B (Cloudflare, GitHub)
- **C√¥ng vi·ªác n·∫∑ng**: Llama 3.1 70B (Cerebras)
- **Multimodal**: GPT-4o mini (GitHub Models)
- **Coding**: Claude 3.5 (OpenRouter free)

#### 4. **Theo D√µi Usage**
```bash
# T·∫°o script theo d√µi quota
#!/bin/bash
echo "=== QUOTA CHECK $(date) ==="
echo "Cerebras: $(curl -s -H "Authorization: Bearer $CEREBRAS_API_KEY" \
  https://api.cerebras.ai/v1/user | jq -r '.limits.remaining')"
echo "Cloudflare: Check dashboard manually"
echo "GitHub: Check models.inference.ai.azure.com"
```

---

### üî• NGU·ªíN ƒê·∫∂C BI·ªÜT: PUTER.JS

**Puter.js** cung c·∫•p API unlimited kh√¥ng c·∫ßn API key:

```javascript
import { AI } from "puter";

const completion = await AI.chat.completions.create({
    messages: [
        { role: "user", content: "Xin ch√†o!" }
    ],
    model: "claude-3.5-sonnet",
    max_tokens: 1000,
});

// Ho·∫∑c OpenAI compatible
const client = new AI.OpenAI({
    apiKey: "puter", // Dummy key
    baseURL: "https://api.puter.com/v1"
});
```

**∆Øu ƒëi·ªÉm**: 
- ‚úÖ Kh√¥ng c·∫ßn ƒëƒÉng k√Ω, kh√¥ng c·∫ßn API key
- ‚úÖ Access mi·ªÖn ph√≠ c√°c model cao c·∫•p
- ‚úÖ Kh√¥ng gi·ªõi h·∫°n requests
- ‚ö†Ô∏è C√≥ th·ªÉ b·ªã rate limit khi qu√° t·∫£i

---

### üìà D·ª∞ PH√íNG KHI H·∫æT QUOTA

#### 1. **Local Fallback v·ªõi Ollama**
```bash
# C√†i ƒë·∫∑t Ollama
curl -fsSL https://ollama.ai/install.sh | sh
ollama pull llama3.2:3b
ollama serve

# C·∫•u h√¨nh Open WebUI
Base URL: http://localhost:11434
```

#### 2. **Backup Models**
- **Ollama**: llama3.2 3B (1.2GB RAM)
- **Oobabooga**: WebUI local v·ªõi nhi·ªÅu models
- **LM Studio**: Desktop app cho Mac/Windows

---

### üí° TIPS V√Ä TH·ª¶ THU·∫¨T

#### 1. **T·ªëi ∆Øu Token**
```
- D√πng "Compression" trong Open WebUI
- B·∫≠t "Function calling" ƒë·ªÉ tr√°nh context d√†i
- Split long conversations
```

#### 2. **Ph√¢n T√°n R·ªßi Ro**
```
- ƒêƒÉng k√Ω 5-7 ngu·ªìn kh√°c nhau
- Kh√¥ng ph·ª• thu·ªôc 100% v√†o 1 ngu·ªìn
- Theo d√µi status pages c·ªßa t·ª´ng ngu·ªìn
```

#### 3. **C·∫≠p Nh·∫≠t Li√™n T·ª•c**
```bash
# Theo d√µi GitHub repo ƒë·ªÉ c·∫≠p nh·∫≠t
https://github.com/cheahjs/free-llm-api-resources
```

---

### ‚ö° TH·ª∞C H√ÄNH NHANH (5 Ph√∫t Setup)

```bash
# 1. ƒêƒÉng k√Ω Cerebras (5 ph√∫t)
# - V√†o cerebras.ai
# - Sign up ‚Üí API Keys ‚Üí Create new key
# - Copy key

# 2. Test ngay trong Open WebUI
# Settings ‚Üí Connections ‚Üí Add Connection
# Base URL: https://api.cerebras.ai/v1
# API Key: [paste your key]
# Model: llama-3.1-70b
# Test: "Xin ch√†o, b·∫°n l√† ai?"

# 3. Th√™m Cloudflare (backup)
# T∆∞∆°ng t·ª± v·ªõi Cloudflare Workers AI
```

---

### üîó LINKS QUAN TR·ªåNG

- **Status Pages**: 
  - Cerebras: https://status.cerebras.ai
  - Cloudflare: https://www.cloudflarestatus.com
  - GitHub: https://www.githubstatus.com

- **Community**:
  - Reddit: r/LocalLLaMA, r/singularity
  - Discord: Open WebUI community
  - GitHub Discussions

- **Documentation**:
  - LiteLLM: https://docs.litellm.ai
  - Open WebUI: https://github.com/open-webui/open-webui

---

### üìù GHI CH√ö C·∫¨P NH·∫¨T

- **11/2025**: Cerebras tƒÉng quota l√™n 1M tokens/ng√†y
- **10/2025**: GitHub Models h·ªó tr·ª£ BYOK (Bring Your Own Key)
- **09/2025**: Cloudflare Workers AI ·ªïn ƒë·ªãnh, kh√¥ng thay ƒë·ªïi limit
- **08/2025**: OpenRouter c·∫≠p nh·∫≠t rate limits cho free tier

---

**üí° K·∫øt lu·∫≠n**: V·ªõi setup ƒë√∫ng c√°ch, b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng AI mi·ªÖn ph√≠ v·ªõi quota >10 tri·ªáu tokens/th√°ng m√† kh√¥ng c·∫ßn th·∫ª t√≠n d·ª•ng. ∆Øu ti√™n Cerebras + Cloudflare + GitHub Models l√† b·ªô ba ho√†n h·∫£o cho nhu c·∫ßu c√° nh√¢n.